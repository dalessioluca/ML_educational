{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determinantal Point Processes (DPP) for physicist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a brief introduction to DPP. We are interested in practical application and therefore we focus on the so-called $L_{ensamble}$. \n",
    "\n",
    "The main idea is that DPP are an elegant way to include repulsion between elements. The only thing you need is to specify the **similarity symmetric matrix $L$** where $L$ is positive semidefinite, i.e. **all its eigenvalues are non-negative**.\n",
    "1. The similarity matrix $L$ has size $N \\times N$. For example, if there are $N$ locations on a line the matrix $L$ gives the similarity between any to pair of locations. To achieve particle repulsion we assume that $L_{i,i}=1$ and $L_{i,j}$ decays with the cartesian distance between locations $i$ and $j$. A common choice is to use a gaussian kernel: $L_{i,j}=\\exp[-\\gamma d(i,j)^2]$. This matrix is positive semi-definite. Another common choice is $L_{i,j}=v_i \\cdot v_j$ where $v_i, v_j$ are the vectors corresponding to elements $i,j$ respectively.\n",
    "2. The fundamental property of DPP is that the probability of selecting any subset $Y$ of particles is $P(Y)\\propto det(L_Y)$ where $L_Y$ is the similarity matrix restricted to the rows and columns corresponding to the few particles selected. Neglecting the normalizing constant for a second we see that the probability of selecting just one particle at location $i$ is $P(i) = L_{i,i}$ and the probability of selecting only two particles at locations $i,j$ is $P(i,j) = L_{i,i}L_{j,j}-L_{i,j}L_{j,i} = P(i)P(j) - L_{i,j}^2 \\le P(i)P(j)$, i.e. the particle repeal each other. \n",
    "4. The normalization constant is $\\sum_Y det(L_Y) = det(L+I)$. For example if there are only two locations then there are only 4 possibility: zero particle, one particle at 1, one particle at 2, two particles at 1 and 2. Then we have\n",
    "\\begin{equation}\n",
    "\\sum_Y det(L_Y)= 1 + L_{1,1} + L_{2,2} + \\left(L_{1,1}L_{2,2} - L_{1,2}L_{2,1}\\right) = (L_{1,1}+1)(L_{2,2}+1)- L_{1,2}L_{2,1} = det(L+I).\n",
    "\\end{equation}\n",
    "Note that we have adopted the convention that the determinant of the empy matrix is $1$, i.e. $det(L_{Y=\\text{empty}})=1$. \n",
    "\n",
    "Note that DPP are probability distribution over all possible subsets of $N$ elements. Obviously the number of such subsets scales exponentially in $N$ but, amazingly, the normalization constant can be computed in $\\mathcal{O}(N^3)$ operations (any determinant can be computed by LU-factorization). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling from DPP intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very nice property of DPP is that an efficient sampling algorithm exists. \n",
    "\n",
    "We can use physics to provide the intuition. Suppose that you consider a system of **non-interacting fermions** with Hamiltonian $H=-L$. In this scenario $-L_{i,i}$ describes the external potential at site $i$ and $-L_{i,j}$ describes the hopping between site $i$ and $j$. Now you diagonalize $H$ to obtain its eigenvalues and eigenvectors $\\lambda_i,v_i$. \n",
    "In physics any configuration (i.e. wave-function) of $n$ **non-interacting fermions** can be obtained by filling $n$ single-particle eigenstates and by **anti-symmetrize**. The total energy of the configuration is $E=\\sum \\lambda_i$ and the probability of that configuration is $p\\propto exp[-\\beta E] = exp[-\\beta \\sum_i \\lambda_i ] = \\prod_i f(\\lambda_i)$ where $f(\\lambda)\\equiv \\exp[-\\beta \\lambda]$. \n",
    "\n",
    "The idea is the same for DPP with the difference that the function $f(\\lambda)$ is not an exponentail but it is linear, i.e. $f(\\lambda)\\equiv\\lambda$. This is necessary since in the DPP the probability is proportional to the determinant which is just the product of the eigenvalues. \n",
    "\n",
    "So if we want to sample the location of particles according to a DPP process we should:\n",
    "1. select a subset of $n$ eigenstate with probability $p\\propto \\prod \\lambda_i $ \n",
    "2. sample the location of the particles according to that anti-symmetrized wave-function.\n",
    "In the math literature, this approach is based on the fact that **DPPs are Mixtures of Elementary DPPs**. In step (1) we select the mixture (of eigenstate) and in step (2) we sample from that mixture without worrying about the values of the selected eigenvalues.\n",
    "\n",
    "For example, let us say, that you selected the eigenstates $v_1,v_5,v_7$ with probability $p\\propto \\lambda_1 \\times \\lambda_5 \\times \\lambda_7$. Now you have to sample the location x,y,z of these three particles correspong to the wave-function \n",
    "\\begin{equation}\n",
    "\\psi(x,y,z)= \\frac{1}{\\sqrt 3} det \\begin{bmatrix}v_1(x) & v_1(y) & v_1(z) \\\\v_5(x) & v_5(y) & v_5(z) \\\\ v_7(x) & v_7(y) & v_7(z) \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Step (1) is trivial. Step (2) on the other hand is still difficult because we do NOT want to work with the full wave-function. If there are 100 locations on the line to choose from the three-particles wave-function above has $100^3=10^6$ distinct values. The brute force approach would be to use the three selected eigenstates to compute the $10^6$ entries for the matrix $M_{i,j,k}$ and then select one entry proportionally to its value. The selected entry would specify, at once, the locations of the three particles. **This, all at one approach, scales badly with the number $n$ of particles** (the total wave-function has $N^n$ values). We would much rather **sample one particle at the time and then update the wave-function to take into account the previous choices**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling from Elementary DPP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue From page 18 in Determinantal point processes for machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us assume that we have spectrally decomposed $L$ into $L=V D V^T$ where $D=\\text{diag}(\\lambda_1,\\lambda_2,...,\\lambda_L)$ and $V$ **contains as columns the eigenvectors of $L$**, i.e. $L V_\\alpha = \\lambda_\\alpha V_\\alpha$. Note that $L,V$ are $N \\times N$ and the determinant of $det(L)=\\prod_i^N \\lambda_i$. \n",
    "\n",
    "\\begin{equation}\n",
    "K =\\sum_i^N \\frac{\\lambda_i}{\\lambda_1+1} v_i v_i^T\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "In step (1) (see above) you have selected a particular set of eigenvectors $V_J = \\{v_n : n \\in J\\}$. Now you have to sample from the elementary DPP with similarity matrix $L_J = V_J V_J^T$ where $V_J$ is a matrix of size $|J|\\times N$, i.e. $V_J$ is tall matrix and $V_J^T$ is wide matrix:\n",
    "\n",
    "\\begin{equation}\n",
    "L_{J} = V_J V_J^T = \\sum_{n \\in J} v_n v_n^T\n",
    "\\end{equation}\n",
    "Note that $L_{J}$ is a $N \\times N$ **square similarity matrix which defines a valid DPP**.\n",
    "\n",
    "As we have argued at the beginning the fundamental property of the DPP is that $P(i)=det(L_{i,i})=L_{i,i}$. From the spectal decomposition of $L_J$ we see that we can choose the location of the first particle $i$ with probability:\n",
    "\n",
    "\\begin{equation}\n",
    "P(i)=(L_{J})_{i,i} = e_i^T L_{J} e_i = \\sum_{n \\in J} (v_n\\cdot e_i)^2 =\\sum_{n \\in J} v_n(i)^2\n",
    "\\end{equation}\n",
    "where $e_i$ is the column vector with all-zeros except one 1 at the location $i$. \n",
    "Now we have to condition the DPP given the fact that we have chosen location $i$ for the first particle. Lukily DPP are closed under conditioning, i.e. after conditioning you get a new DPP. **Therefore the process can continue iteratively:**\n",
    "1. select location $i$ according to $P(i)=(L_J)_{i,i}$ \n",
    "2. condition $L_J$ to obtain a new $L_{(J-1)}$\n",
    "\n",
    "<img src=\"./figure/DPP_conditioning_figure.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is to express the conditioning in terms of the eigenvectors $v_n$. \n",
    "The brute force would be "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the algorithm to sample a DPP\n",
    "\n",
    "<img src=\"./figure/sample_DPP.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "class dpp():\n",
    "    def __init__(self):\n",
    "        self.lenght = None \n",
    "        self.D  = None \n",
    "        self.V  = None\n",
    "    \n",
    "    def sample(self,k=None,verbose=False) -> list:\n",
    "        \"\"\"\n",
    "        Sample the DPP and returns the locations of the DPP particles.\n",
    "        If k is provided exactly k locations are returned\n",
    "        \"\"\"\n",
    "            \n",
    "        # PHASE 1: select the eigenvectors\n",
    "        if(k==None):\n",
    "            # Select each eigenvectors with probability lambda/(1+lambda)\n",
    "            prob = np.divide(self.D,1+self.D)\n",
    "            x = np.random.rand(prob.size)\n",
    "            v = np.argwhere(x<prob)\n",
    "            k = len(v)    \n",
    "            V = self.V[:, v]\n",
    "            V = V.reshape(self.lenght,-1)\n",
    "        elif(k==self.length):\n",
    "            #select all the eigenvectors\n",
    "            k=self.lenght\n",
    "            V=self.V\n",
    "        elif(k>self.lenght):\n",
    "            # error: Cannot sample more than self.lenght DPP particles\n",
    "            print(\"Error: k>self.lenght\")\n",
    "            sys.exit()\n",
    "        else:\n",
    "            # select exactly k eigenvectors\n",
    "            print(\"Error: Not implemented yet\")\n",
    "            sys.exit()\n",
    "        \n",
    "        if(verbose):\n",
    "            print(\"I will select \"+str(k)+\" points:\")\n",
    "            \n",
    "            \n",
    "        # PHASE 2: Select iteratively a location\n",
    "        #ground_set, rem_set = np.arange(N), np.full(N, True)\n",
    "        locations = list(np.arange(0,self.lenght))\n",
    "        chosen=[]\n",
    "    \n",
    "        for n in range(0,k):\n",
    "            # compute probabilities for each item\n",
    "            prob=np.linalg.norm(V,ord=None,axis=1)**2/(k-n) #this is probability of choosing each location\n",
    "            prob=prob.flatten()\n",
    "            \n",
    "            # select one location from the available_one \n",
    "            loc = np.random.choice(locations,size=1, p=prob.flatten()).item()\n",
    "            chosen.append(loc)\n",
    "            if(verbose):\n",
    "                print(\"add location\",loc)\n",
    "            \n",
    "            if(len(chosen)==k):\n",
    "                if(verbose):\n",
    "                    print(\"chosen points:\",chosen)\n",
    "                return chosen\n",
    "            else:\n",
    "                \n",
    "                # V is a ortonormal basis.\n",
    "                # Now I need to find a new ortonormal basis for the subspace of V perpendicular to e_loc\n",
    "                # The constraint that the subspace spanned by V is hortogonal to e_loc is:\n",
    "                # (c1 V_1 + c2 V_2 + c_k V_k) cdot e_loc = 0 \n",
    "                # This is equivalent to:\n",
    "                # c1 V_1(loc) + c2 V_2(loc) + c_k V_k(loc) = 0\n",
    "                # This subspace has dimension k-1 since the coefficients c1,...,ck are now constrained.\n",
    "                # I need to find a new ortonormal basis for this subspace.\n",
    "                # \n",
    "                # The procedure is as follow:\n",
    "                # e_loc = c1* V_1 + c2* V_2 + ... + ck* V_k \n",
    "                # The coeff of this decomposition are already available (read off the entry of the vectors):\n",
    "                # cn* = <e_loc,V_n> = V_n(loc)\n",
    "                # Build k-1 vectors in the subspace of V perpendicular to e_loc by doing:\n",
    "                # U_n = V_n - V_1 (cn*/c1*) for n=2,k\n",
    "                # Note that: <U_n | e_loc> = cn* - c1* (cn*/c1*) = 0\n",
    "                # Feed these k-1 vectors into a Gram–Schmidt procedure to obtain a hortonormal basis\n",
    "                # The procedure above works only is c1* is different from zero.\n",
    "                # For this reason I save myself some problem by choosing V1 as the vector with the largest coeff.\n",
    "                # Recall that:\n",
    "                # N, k = V.shape\n",
    "                \n",
    "                cstar=V[loc,:] #for each one of the k eigenvectors I have a cstar \n",
    "                j  = np.argmax(cstar)\n",
    "                Vj = V[:,j] # select the special vector\n",
    "                cj = Vj[loc]\n",
    "                cstar = np.delete(cstar,j)\n",
    "                V = np.delete(V,j,axis=1)\n",
    "                \n",
    "                # Next I do a vectorized form for:\n",
    "                # U[0:N,0:k-1] = V[0:N,0:k-1] - Vj[0:N] (cstar[0:k-1]/cj)\n",
    "                V=V-np.matmul(Vj.reshape(-1,1),(cstar/cj).reshape(1,-1))\n",
    "                     \n",
    "                # Gram–Schmidt procedure to find a basis out of the representative vectors\n",
    "                basis = []\n",
    "                for l in range(k-n-1):\n",
    "                    v=V[:,l]\n",
    "                    w = v - np.sum( np.dot(v,b)*b  for b in basis )\n",
    "                    basis.append(w/np.linalg.norm(w))\n",
    "                V=np.array(basis).T\n",
    "                if(verbose):\n",
    "                    print(\"len(basis)\",len(basis))\n",
    "        \n",
    "        \n",
    "class dpp_line(dpp):\n",
    "    def __init__(self, lenght=10, sigma2=1, bc='PBC'):\n",
    "        super().__init__()\n",
    "        self.lenght = lenght\n",
    "        data = np.zeros([lenght,1])\n",
    "        data[:,0]=np.arange(0,lenght)\n",
    "        if(bc == 'PBC'):\n",
    "            gamma = 1.0/(2.0*sigma2)\n",
    "            self.M= np.zeros((self.lenght,self.lenght))\n",
    "            for n1 in range(0,self.lenght):\n",
    "                self.M[n1,n1]= 1.0\n",
    "                for n2 in range(n1+1,self.lenght):\n",
    "                    dx =(data[n1,0]-data[n2,0]+self.lenght ) % self.lenght\n",
    "                    dx = min(dx, self.lenght - dx)\n",
    "                    d2=dx*dx\n",
    "                    tmp = np.exp(-gamma*d2)\n",
    "                    self.M[n1,n2]= tmp\n",
    "                    self.M[n2,n1]= tmp\n",
    "        elif(bc == 'OBC'):\n",
    "            gamma = 1.0/(2.0*sigma2)\n",
    "            self.M= rbf_kernel(data,data,gamma)\n",
    "        else:\n",
    "            print(\"ERROR: Unknown bc =\",bc)\n",
    "        self.D, self.V  = np.linalg.eig(self.M)\n",
    "        \n",
    "    def sample(self,k=None,verbose=False):\n",
    "        chosen = np.array(super().sample(k,verbose))\n",
    "        return chosen\n",
    "\n",
    "class dpp_plane(dpp):\n",
    "    def __init__(self, lx=10, ly=10, sigma2=1, bc='PBC'):\n",
    "        super().__init__()\n",
    "        \n",
    "        data = np.zeros((lx,ly,2))\n",
    "        for ix in range(lx):\n",
    "            data[ix,:,0]=ix\n",
    "        for iy in range(ly):\n",
    "            data[:,iy,1]=iy\n",
    "        data=data.reshape(-1,2)\n",
    "        self.data=data\n",
    "        self.lenght = lx*ly\n",
    "        self.lx = lx\n",
    "        self.ly = ly\n",
    "        if(bc == 'PBC'):\n",
    "            gamma = 1.0/(2.0*sigma2)\n",
    "            self.M= np.zeros((self.lenght,self.lenght))\n",
    "            for n1 in range(0,self.lenght):\n",
    "                self.M[n1,n1]= 1.0\n",
    "                for n2 in range(n1+1,self.lenght):\n",
    "                    dx =(data[n1,0]-data[n2,0]+self.lx ) % self.lx\n",
    "                    dx = min(dx, self.lx - dx)\n",
    "                    dy =(data[n1,1]-data[n2,1]+self.ly ) % self.ly\n",
    "                    dy = min(dy, self.ly - dy)\n",
    "                    d2=dx*dx+dy*dy\n",
    "                    tmp = np.exp(-gamma*d2)\n",
    "                    self.M[n1,n2]= tmp\n",
    "                    self.M[n2,n1]= tmp\n",
    "        elif(bc == 'OBC'):\n",
    "            gamma = 1.0/(2.0*sigma2)\n",
    "            self.M= rbf_kernel(data,data,gamma)\n",
    "        else:\n",
    "            print(\"ERROR: Unknown bc =\",bc)\n",
    "        self.D, self.V  = np.linalg.eig(self.M)\n",
    "\n",
    "        \n",
    "    def sample(self,k=None,verbose=False):\n",
    "        chosen_list = super().sample(k,verbose)\n",
    "        xy_pair=np.array(self.data[chosen_list])\n",
    "        return xy_pair\n",
    "        \n",
    "    \n",
    "class random():\n",
    "    def __init__(self):\n",
    "        self.lenght = None\n",
    "    \n",
    "    def sample(self,k=None) -> list:\n",
    "        \"\"\"\n",
    "        Sample k random locations without replacement\n",
    "        A list of locations is returned\n",
    "        \"\"\"\n",
    "        chosen=np.random.choice(range(self.lenght),size=k,p=None).tolist()\n",
    "        return chosen\n",
    "\n",
    "class random_line(random):\n",
    "    def __init__(self, lenght=10):\n",
    "        super().__init__()\n",
    "        self.lenght = lenght\n",
    "    def sample(self,k=5):\n",
    "        chosen = np.array(super().sample(k))\n",
    "        return chosen\n",
    "    \n",
    "class random_plane(random):\n",
    "    def __init__(self, lx=10, ly=10):\n",
    "        super().__init__()\n",
    "        data = np.zeros((lx,ly,2))\n",
    "        for ix in range(lx):\n",
    "            data[ix,:,0]=ix\n",
    "        for iy in range(ly):\n",
    "            data[:,iy,1]=iy\n",
    "        data=data.reshape(-1,2)\n",
    "        self.data=data\n",
    "        self.lenght = lx*ly\n",
    "    \n",
    "    def sample(self,k=10):\n",
    "        chosen_list = super().sample(k)\n",
    "        xy_pair=np.array(self.data[chosen_list])\n",
    "        return xy_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13  4 23  9  1 11  2 16 21  8]\n"
     ]
    }
   ],
   "source": [
    "dpp=dpp_line(lenght=25,sigma2=1, bc='PBC')\n",
    "xy_dpp=dpp.sample(verbose=False)\n",
    "print(xy_dpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lx = 20\n",
    "ly = 20\n",
    "dpp=dpp_plane(lx=lx,ly=ly,sigma2=100,bc='PBC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_points: dpp vs random 27 27\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xy_dpp=dpp.sample(verbose=False)\n",
    "n_points_dpp = xy_dpp.shape[0]\n",
    "\n",
    "random2=random_plane(lx,ly)\n",
    "xy_random=random2.sample(n_points_dpp)\n",
    "n_points_random = xy_random.shape[0]\n",
    "\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, subplot_kw = {'aspect' : 1.0})\n",
    "ax1.scatter(xy_dpp[:,0],xy_dpp[:,1])\n",
    "ax1.set_title('DPP')\n",
    "ax2.scatter(xy_random[:,0],xy_random[:,1])\n",
    "ax2.set_title('random without replacement')\n",
    "print(\"N_points: dpp vs random\",n_points_dpp,n_points_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyro]",
   "language": "python",
   "name": "conda-env-pyro-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
